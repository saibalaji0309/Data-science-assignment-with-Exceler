{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c28b99-2d8b-4078-81c0-2d23dbd57f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Alphabets_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bd67c1-7473-4a4b-9354-1f7af0ad5194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    0\n",
       "xbox      0\n",
       "ybox      0\n",
       "width     0\n",
       "height    0\n",
       "onpix     0\n",
       "xbar      0\n",
       "ybar      0\n",
       "x2bar     0\n",
       "y2bar     0\n",
       "xybar     0\n",
       "x2ybar    0\n",
       "xy2bar    0\n",
       "xedge     0\n",
       "xedgey    0\n",
       "yedge     0\n",
       "yedgex    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4af6e1-6532-4090-aefc-40c33d4607d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>I</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>X</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19948</th>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>O</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19975</th>\n",
       "      <td>E</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19987</th>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "627        I     3     7      4       5      2     7     7      0      7   \n",
       "724        L     3     6      3       4      1     1     0      6      6   \n",
       "730        I     1     9      0       6      0     7     7      4      4   \n",
       "910        X     5    11      6       8      2     7     7      5      4   \n",
       "943        O     2     3      2       1      1     8     7      6      4   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19948      T     4     5      4       4      2     6    11      2      7   \n",
       "19950      O     4     5      5       4      3     7     7      8      5   \n",
       "19975      E     1     0      1       0      0     5     8      5      7   \n",
       "19987      L     3     7      3       5      1     0     1      6      6   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "627       13       6       8      0       8      1       7  \n",
       "724        0       1       5      0       8      0       8  \n",
       "730        7       6       8      0       8      0       8  \n",
       "910        7       6       8      3       8      4       8  \n",
       "943        9       6       8      2       8      3       8  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19948     11       9       4      1      11      2       4  \n",
       "19950      7       6       8      2       8      3       8  \n",
       "19975      7       6      12      0       8      6      10  \n",
       "19987      0       0       6      0       8      0       8  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "\n",
       "[1332 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9bc1ab4-c658-4500-b17c-2b133b61e87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [letter, xbox, ybox, width, height, onpix, xbar, ybar, x2bar, y2bar, xybar, x2ybar, xy2bar, xedge, xedgey, yedge, yedgex]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(keep=False,inplace=True)\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edcac7b8-2f46-4b7f-b0a6-0e3cd2b122df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter    object\n",
       "xbox       int64\n",
       "ybox       int64\n",
       "width      int64\n",
       "height     int64\n",
       "onpix      int64\n",
       "xbar       int64\n",
       "ybar       int64\n",
       "x2bar      int64\n",
       "y2bar      int64\n",
       "xybar      int64\n",
       "x2ybar     int64\n",
       "xy2bar     int64\n",
       "xedge      int64\n",
       "xedgey     int64\n",
       "yedge      int64\n",
       "yedgex     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c581775-aea5-44fd-926e-8672b824d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = df.iloc[:, 1:]\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['letter'] = label_encoder.fit_transform(df['letter'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6391faef-70d8-4842-894c-11ef3b3b7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['letter']  # Features\n",
    "y = df.iloc[:,1:]  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af516129-5af4-418f-bdb5-19ed989bf784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalli\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1431 - loss: 3820.5964\n",
      "Epoch 2/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1204 - loss: 73800.1953\n",
      "Epoch 3/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1182 - loss: 249390.2500\n",
      "Epoch 4/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1137 - loss: 534727.8750\n",
      "Epoch 5/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1158 - loss: 904758.8750\n",
      "Epoch 6/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1161 - loss: 1378651.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1213 - loss: 1948748.3750\n",
      "Epoch 8/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1212 - loss: 2586467.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1247 - loss: 3329083.5000\n",
      "Epoch 10/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1201 - loss: 4155803.7500\n",
      "Epoch 11/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1272 - loss: 5087635.5000\n",
      "Epoch 12/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1301 - loss: 6042575.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1302 - loss: 7218413.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1279 - loss: 8379753.5000\n",
      "Epoch 15/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1341 - loss: 9673576.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1227 - loss: 11162555.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1263 - loss: 12477435.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1349 - loss: 14208912.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1213 - loss: 15868022.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1248 - loss: 17605476.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1233 - loss: 19535584.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1355 - loss: 21577524.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1210 - loss: 23670812.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1340 - loss: 26310476.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1252 - loss: 28686724.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1274 - loss: 30622542.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1219 - loss: 33685780.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1219 - loss: 35952392.0000\n",
      "Epoch 29/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1323 - loss: 38761416.0000\n",
      "Epoch 30/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1264 - loss: 42013560.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1258 - loss: 45167480.0000\n",
      "Epoch 32/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1284 - loss: 48507760.0000\n",
      "Epoch 33/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1290 - loss: 52148700.0000\n",
      "Epoch 34/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1222 - loss: 55455024.0000\n",
      "Epoch 35/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1238 - loss: 59051516.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1334 - loss: 62297556.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1276 - loss: 65809812.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1314 - loss: 69867608.0000\n",
      "Epoch 39/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1265 - loss: 73575496.0000\n",
      "Epoch 40/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1312 - loss: 78561800.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1301 - loss: 83122272.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1312 - loss: 87618944.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1185 - loss: 92588264.0000\n",
      "Epoch 44/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1148 - loss: 97831624.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1257 - loss: 102788552.0000\n",
      "Epoch 46/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1099 - loss: 107657648.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1300 - loss: 114122320.0000\n",
      "Epoch 48/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1253 - loss: 119490296.0000\n",
      "Epoch 49/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1195 - loss: 124763224.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1150 - loss: 129261184.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1218 - loss: 137153488.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1224 - loss: 144271840.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1162 - loss: 149419968.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1374 - loss: 155483632.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1059 - loss: 162956160.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1146 - loss: 170161696.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1247 - loss: 177951280.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1288 - loss: 186733312.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1105 - loss: 193125024.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1175 - loss: 200901744.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 207850832.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1156 - loss: 215540144.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1153 - loss: 223721616.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1210 - loss: 232825328.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1197 - loss: 241743120.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1178 - loss: 251453136.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1168 - loss: 263150128.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1170 - loss: 274703584.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1070 - loss: 284036192.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1123 - loss: 292166368.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1165 - loss: 305330144.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1222 - loss: 313018080.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1111 - loss: 322949920.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1089 - loss: 339919264.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1117 - loss: 345198016.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1158 - loss: 357610464.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1121 - loss: 370459552.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1081 - loss: 377700448.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1136 - loss: 394169824.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1160 - loss: 407538176.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 419865408.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1030 - loss: 432124384.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1172 - loss: 446637184.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 459287296.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1048 - loss: 472013344.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1095 - loss: 488598240.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1105 - loss: 506965888.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1135 - loss: 520706080.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1088 - loss: 527657984.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1117 - loss: 537473280.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1154 - loss: 555022528.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1052 - loss: 571335360.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1090 - loss: 585079104.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1075 - loss: 608276800.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1098 - loss: 624782144.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1112 - loss: 644519168.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1138 - loss: 663141632.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1162 - loss: 669587200.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1163 - loss: 698842240.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1148 - loss: 717351744.0000\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Accuracy: 0.016795231\n",
      "Precision: 0.99971366\n",
      "Recall: 0.062249247\n",
      "F1-Score: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.7684057\n",
      " 0.         0.         0.         0.05065666]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100)\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model.predict(X_test))\n",
    "\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b40cc20b-10ba-4a97-b887-63345a395870",
   "metadata": {},
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a function to create the model\n",
    "def create_model(hidden_layer_sizes=(64,), activation='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_sizes[0], input_dim=X_train.shape[1], activation=activation))\n",
    "    for size in hidden_layer_sizes[1:]:\n",
    "        model.add(Dense(size, activation=activation))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassifier\n",
    "model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,50), (100,50), (100,100)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [20, 50]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "clf = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found by GridSearchCV\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_model = clf.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Plotting learning curve if needed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(clf.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Hyperparameter combinations')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee50f392-422f-4593-b837-765993ba2790",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define the basic model\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,50), (100,50), (100,100)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found by GridSearchCV\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_mlp = clf.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# You can also plot the learning curve if needed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(clf.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Hyperparameter combinations')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "030c7c63-b6a4-4057-8f9e-bdb8241b57d2",
   "metadata": {},
   "source": [
    "# 1. Varying the number of hidden layers:\n",
    "\n",
    "# Model with 3 hidden layers\n",
    "model_3_layers = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu', input_shape=(df.shape[1],)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(df.shape[1], activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model_3_layers.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_3_layers.fit(X_train, y_train, epochs=30)\n",
    "# accuracy = tf.keras.metrics.Accuracy()(y_test, model_3_layers.predict(X_test))\n",
    "# precision = tf.keras.metrics.Precision()(y_test, model_3_layers.predict(X_test))\n",
    "# recall = tf.keras.metrics.Recall()(y_test, model_3_layers.predict(X_test))\n",
    "# f1_score = tf.keras.metrics.F1Score()(y_test, model_3_layers.predict(X_test))\n",
    "\n",
    "# print('model_3_layers')\n",
    "# print(\"Accuracy:\", accuracy.numpy())\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())\n",
    "# print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "# Model with 4 hidden layers\n",
    "model_4_layers = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu', input_shape=(df.shape[1],)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(df.shape[1], activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model_4_layers.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30)\n",
    "# accuracy = tf.keras.metrics.Accuracy()(y_test, model_4_layers.predict(X_test))\n",
    "# precision = tf.keras.metrics.Precision()(y_test, model_4_layers.predict(X_test))\n",
    "# recall = tf.keras.metrics.Recall()(y_test, model_4_layers.predict(X_test))\n",
    "# f1_score = tf.keras.metrics.F1Score()(y_test, model_4_layers.predict(X_test))\n",
    "\n",
    "# print('model_4_layers')\n",
    "# print(\"Accuracy:\", accuracy.numpy())\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())\n",
    "# print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "\n",
    "# Train and evaluate both models and compare their performance\n",
    "\n",
    "# 2. Varying the number of neurons per hidden layer:\n",
    "\n",
    "# Model with 256 neurons per hidden layer\n",
    "model_256_neurons = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(256, activation='relu', input_shape=(df.shape[1],)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(df.shape[1], activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model_256_neurons.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30)\n",
    "# accuracy = tf.keras.metrics.Accuracy()(y_test, model_256_neurons.predict(X_test))\n",
    "# precision = tf.keras.metrics.Precision()(y_test, model_256_neurons.predict(X_test))\n",
    "# recall = tf.keras.metrics.Recall()(y_test, model_256_neurons.predict(X_test))\n",
    "# f1_score = tf.keras.metrics.F1Score()(y_test, model_256_neurons.predict(X_test))\n",
    "\n",
    "# print('model_256_neurons')\n",
    "# print(\"Accuracy:\", accuracy.numpy())\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())\n",
    "# print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "\n",
    "# Model with 512 neurons per hidden layer\n",
    "model_512_neurons = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(512, activation='relu', input_shape=(df.shape[1],)),\n",
    "  tf.keras.layers.Dense(512, activation='relu'),\n",
    "  tf.keras.layers.Dense(df.shape[1], activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model_512_neurons.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_512_neurons.fit(X_train, y_train, epochs=30)\n",
    "# accuracy = tf.keras.metrics.Accuracy()(y_test, model_512_neurons.predict(X_test))\n",
    "# precision = tf.keras.metrics.Precision()(y_test, model_512_neurons.predict(X_test))\n",
    "# recall = tf.keras.metrics.Recall()(y_test, model_512_neurons.predict(X_test))\n",
    "# f1_score = tf.keras.metrics.F1Score()(y_test, model_512_neurons.predict(X_test))\n",
    "\n",
    "# print('model_512_neurons')\n",
    "# print(\"Accuracy:\", accuracy.numpy())\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())\n",
    "# print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "# Train and evaluate both models and compare their performance\n",
    "\n",
    "# 3. Trying different activation functions:\n",
    "\n",
    "# Model with sigmoid activation\n",
    "model_sigmoid = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='sigmoid', input_shape=(df.shape[1],)),\n",
    "  tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(df.shape[1], activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model_sigmoid.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_sigmoid.fit(X_train, y_train, epochs=30)\n",
    "# accuracy = tf.keras.metrics.Accuracy()(y_test, model_sigmoid.predict(X_test))\n",
    "# precision = tf.keras.metrics.Precision()(y_test, model_sigmoid.predict(X_test))\n",
    "# recall = tf.keras.metrics.Recall()(y_test, model_sigmoid.predict(X_test))\n",
    "# f1_score = tf.keras.metrics.F1Score()(y_test, model_sigmoid.predict(X_test))\n",
    "\n",
    "# print('model_sigmoid')\n",
    "# print(\"Accuracy:\", accuracy.numpy())\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())\n",
    "# print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "# Model with tanh activation\n",
    "model_tanh = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='tanh', input_shape=(df.shape[1],)),\n",
    "  tf.keras.layers.Dense(64, activation='tanh'),\n",
    "  tf.keras.layers.Dense(df.shape[1], activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model_tanh.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_tanh.fit(X_train, y_train, epochs=30)\n",
    "# accuracy = tf.keras.metrics.Accuracy()(y_test, model_tanh.predict(X_test))\n",
    "# precision = tf.keras.metrics.Precision()(y_test, model_tanh.predict(X_test))\n",
    "# recall = tf.keras.metrics.Recall()(y_test, model_tanh.predict(X_test))\n",
    "# f1_score = tf.keras.metrics.F1Score()(y_test, model_tanh.predict(X_test))\n",
    "\n",
    "# print('model_tanh')\n",
    "# print(\"Accuracy:\", accuracy.numpy())\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())\n",
    "# print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "# Train and evaluate both models and compare their performance\n",
    "\n",
    "# 4. Experimenting with different learning rates:\n",
    "\n",
    "# Model with learning rate of 0.01\n",
    "model_lr_001 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu', input_shape=(df.shape[1],)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(df.shape[1], activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model_lr_001.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_lr_001.fit(X_train, y_train, epochs=30)\n",
    "# accuracy = tf.keras.metrics.Accuracy()(y_test, model_lr_001.predict(X_test))\n",
    "# precision = tf.keras.metrics.Precision()(y_test, model_lr_001.predict(X_test))\n",
    "# recall = tf.keras.metrics.Recall()(y_test, model_lr_001.predict(X_test))\n",
    "# f1_score = tf.keras.metrics.F1Score()(y_test, model_lr_001.predict(X_test))\n",
    "\n",
    "# print('model_lr_001')\n",
    "# print(\"Accuracy:\", accuracy.numpy())\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())\n",
    "# print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "\n",
    "\n",
    "# Model with learning rate of 0.001\n",
    "model_lr_0001 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(128, activation='relu', input_shape=(df.shape[1],)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(df.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model_lr_0001.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_lr_0001.fit(X_train, y_train, epochs=30)\n",
    "# accuracy = tf.keras.metrics.Accuracy()(y_test, model_lr_0001.predict(X_test))\n",
    "# precision = tf.keras.metrics.Precision()(y_test, model_lr_0001.predict(X_test))\n",
    "# recall = tf.keras.metrics.Recall()(y_test, model_lr_0001.predict(X_test))\n",
    "# f1_score = tf.keras.metrics.F1Score()(y_test, model_lr_0001.predict(X_test))\n",
    "\n",
    "# print('model_3_layers')\n",
    "# print(\"Accuracy:\", accuracy.numpy())\n",
    "# print(\"Precision:\", precision.numpy())\n",
    "# print(\"Recall:\", recall.numpy())\n",
    "# print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model_3_layers.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model_3_layers.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model_3_layers.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model_3_layers.predict(X_test))\n",
    "\n",
    "print('model_3_layers')\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model_4_layers.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model_4_layers.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model_4_layers.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model_4_layers.predict(X_test))\n",
    "\n",
    "print('model_4_layers')\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model_256_neurons.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model_256_neurons.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model_256_neurons.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model_256_neurons.predict(X_test))\n",
    "\n",
    "print('model_256_neurons')\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model_512_neurons.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model_512_neurons.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model_512_neurons.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model_512_neurons.predict(X_test))\n",
    "\n",
    "print('model_512_neurons')\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model_sigmoid.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model_sigmoid.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model_sigmoid.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model_sigmoid.predict(X_test))\n",
    "\n",
    "print('model_sigmoid')\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model_tanh.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model_tanh.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model_tanh.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model_tanh.predict(X_test))\n",
    "\n",
    "print('model_tanh')\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model_lr_001.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model_lr_001.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model_lr_001.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model_lr_001.predict(X_test))\n",
    "\n",
    "print('model_lr_001')\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n",
    "\n",
    "accuracy = tf.keras.metrics.Accuracy()(y_test, model_lr_0001.predict(X_test))\n",
    "precision = tf.keras.metrics.Precision()(y_test, model_lr_0001.predict(X_test))\n",
    "recall = tf.keras.metrics.Recall()(y_test, model_lr_0001.predict(X_test))\n",
    "f1_score = tf.keras.metrics.F1Score()(y_test, model_lr_0001.predict(X_test))\n",
    "\n",
    "print('model_3_layers')\n",
    "print(\"Accuracy:\", accuracy.numpy())\n",
    "print(\"Precision:\", precision.numpy())\n",
    "print(\"Recall:\", recall.numpy())\n",
    "print(\"F1-Score:\", f1_score.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66da2c8d-5759-4e5a-b0bf-e44e4ad357c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  8,  3, 13,  6, 18,  1,  0,  9, 12, 23, 14, 17,  5,  2,  7, 22,\n",
       "       11, 15,  4, 21, 24, 16, 20, 10, 25])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letter'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7884ebb1-97dc-4c3c-9e7a-091d294ba9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "letter\n",
       "0     789\n",
       "1     766\n",
       "2     736\n",
       "3     805\n",
       "4     768\n",
       "5     775\n",
       "6     773\n",
       "7     734\n",
       "8     755\n",
       "9     747\n",
       "10    739\n",
       "11    761\n",
       "12    792\n",
       "13    783\n",
       "14    753\n",
       "15    803\n",
       "16    783\n",
       "17    758\n",
       "18    748\n",
       "19    796\n",
       "20    813\n",
       "21    764\n",
       "22    752\n",
       "23    787\n",
       "24    786\n",
       "25    734\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['letter'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0498015e-4779-4011-8582-9e0c9ffb2256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikeras\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from scikeras) (3.3.3)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from scikeras) (1.4.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.3.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3675ee35-6085-486c-8608-0dbb4e70f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\jalli\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jalli\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff5c8d80-00a9-48eb-97fd-a35af6f3582f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'InputLayer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hidden_layers):\n\u001b[1;32m---> 24\u001b[0m     model\u001b[38;5;241m.\u001b[39mInputLayer(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,))\n\u001b[0;32m     25\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(neurons_per_hidden_layer, activation\u001b[38;5;241m=\u001b[39mactivation_function))\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39madd(keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m26\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'InputLayer'"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter grid\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layers': [1, 2, 3],\n",
    "    'neurons_per_hidden_layer': [16, 32, 64],\n",
    "    'activation_functions': ['relu', 'tanh', 'sigmoid'],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Perform grid search\n",
    "\n",
    "for hidden_layers in param_grid['hidden_layers']:\n",
    "    for neurons_per_hidden_layer in param_grid['neurons_per_hidden_layer']:\n",
    "        for activation_function in param_grid['activation_functions']:\n",
    "            for learning_rate in param_grid['learning_rate']:\n",
    "                # Build the model with current hyperparameters\n",
    "                model = keras.Sequential()\n",
    "                for _ in range(hidden_layers):\n",
    "                    model.InputLayer(shape=(None,))\n",
    "                    model.add(keras.layers.Dense(neurons_per_hidden_layer, activation=activation_function))\n",
    "                model.add(keras.layers.Dense(26, activation='softmax'))\n",
    "                model.compile(loss='sparse_categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "                # Train the model\n",
    "                model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "                # Evaluate the model\n",
    "                loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "                # Store the results\n",
    "                results[(hidden_layers, neurons_per_hidden_layer, activation_function, learning_rate)] = {'loss': loss, 'accuracy': accuracy}\n",
    "\n",
    "# Analyze the results to identify the best hyperparameters\n",
    "best_params = None\n",
    "best_accuracy = 0\n",
    "for params, result in results.items():\n",
    "    if result['accuracy'] > best_accuracy:\n",
    "        best_params = params\n",
    "        best_accuracy = result['accuracy']\n",
    "\n",
    "# Print the best hyperparameters and their corresponding accuracy\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8391e3e-85df-48fb-8b7a-57a74d39fb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter activation for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(activation=tanh)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Perform GridSearchCV\u001b[39;00m\n\u001b[0;32m     29\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Best parameters found by GridSearchCV\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest parameters found:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, clf\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter activation for estimator KerasClassifier.\nThis issue can likely be resolved by setting this parameter in the KerasClassifier constructor:\n`KerasClassifier(activation=tanh)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "X = df.drop('letter', axis=1)\n",
    "y = df['letter']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "# Define a function to create the model\n",
    "def create_model(optimizer = 'adam',hidden_layer_sizes=(64,), activation='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_sizes[0], input_dim=X_train.shape[1], activation=activation))\n",
    "    for size in hidden_layer_sizes[1:]:\n",
    "        model.add(Dense(size, activation=activation))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics =['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50,50), (100,50), (100,100)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'learning_rate': [0.001, 0.01],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [20, 50]\n",
    "}\n",
    "\n",
    "# Wrap the model using the custom wrapper\n",
    "model =KerasClassifier(build_fn=create_model, epochs=20, batch_size=32, verbose=3)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "clf = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1,verbose=1, cv=3)\n",
    "clf.fit(X_train, y_train,epochs=30)\n",
    "\n",
    "# Best parameters found by GridSearchCV\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_model = clf.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# Plotting learning curve if needed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(clf.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Hyperparameter combinations')\n",
    "plt.ylabel('Mean Test Score')\n",
    "plt.title('Hyperparameter Tuning Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "604c2939-6e1b-4fd3-9815-092aa6850abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jalli\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Multioutput target data is not supported with label binarization",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLPClassifier\n\u001b[0;32m     13\u001b[0m ann_classifier \u001b[38;5;241m=\u001b[39m MLPClassifier(hidden_layer_sizes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m ann_classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:752\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    736\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \n\u001b[0;32m    738\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03m        Returns a trained MLP model.\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, incremental\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:442\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layer_sizes must be > 0, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m hidden_layer_sizes\n\u001b[0;32m    437\u001b[0m     )\n\u001b[0;32m    438\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoefs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m incremental\n\u001b[0;32m    440\u001b[0m )\n\u001b[1;32m--> 442\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(X, y, incremental, reset\u001b[38;5;241m=\u001b[39mfirst_pass)\n\u001b[0;32m    444\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# Ensure y is 2D\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1123\u001b[0m, in \u001b[0;36mMLPClassifier._validate_input\u001b[1;34m(self, X, y, incremental, reset)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m incremental):\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_binarizer \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_binarizer\u001b[38;5;241m.\u001b[39mfit(y)\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_binarizer\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:299\u001b[0m, in \u001b[0;36mLabelBinarizer.fit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_type_ \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultioutput\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_type_:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultioutput target data is not supported with label binarization\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m     )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has 0 samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y)\n",
      "\u001b[1;31mValueError\u001b[0m: Multioutput target data is not supported with label binarization"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_shape=(X_train.shape[1],)))  # Input layer and first hidden layer\n",
    "model.add(Dense(units=26, activation='softmax'))  \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "ann_classifier = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=100)\n",
    "ann_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90304b99-0695-42ac-8d1b-070ef5fe34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = ann_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fca488-9fd5-4afa-a6d6-5a88c7457a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Defining  the parameter grid here\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04687c36-4953-4b48-b214-cf011abca280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating  a grid search object\n",
    "grid_search = GridSearchCV(ann_classifier, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ad8cd-3b0b-4983-ba22-4f519e7c3d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating  the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc5122-e704-406e-95e1-17e8af8fcece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a84df0-3128-460a-88fb-566cfb5b63b5",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8387be-cc98-4fd4-895d-35c286068293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Default model evaluation\n",
    "y_pred_default = ann_classifier.predict(X_test)\n",
    "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
    "precision_default = precision_score(y_test, y_pred_default, average='weighted')\n",
    "recall_default = recall_score(y_test, y_pred_default, average='weighted')\n",
    "f1_default = f1_score(y_test, y_pred_default, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bcf467-5228-4822-bf21-0f5f1cf1aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned model evaluation\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "precision_tuned = precision_score(y_test, y_pred_tuned, average='weighted')\n",
    "recall_tuned = recall_score(y_test, y_pred_tuned, average='weighted')\n",
    "f1_tuned = f1_score(y_test, y_pred_tuned, average='weighted')\n",
    "# Print the evaluation metrics\n",
    "print(\"Default Model:\")\n",
    "print(\"Accuracy:\", accuracy_default)\n",
    "print(\"Precision:\", precision_default)\n",
    "print(\"Recall:\", recall_default)\n",
    "print(\"F1-score:\", f1_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df769e61-ae07-4e44-8bd1-5c61bf03b38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuned Model:\")\n",
    "print(\"Accuracy:\", accuracy_tuned)\n",
    "print(\"Precision:\", precision_tuned)\n",
    "print(\"Recall:\", recall_tuned)\n",
    "print(\"F1-score:\", f1_tuned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
